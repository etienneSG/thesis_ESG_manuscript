%!TEX root=../../thesis_ESG.tex
\chapter{Numerical experiments}
\label{chap:multi-sourcing:numerical-experiments}


In order to test the efficiency of our approach, we test our method on datasets from Argon Consulting’s clients.
The objective is to compare the multi-sourcing currently in use by the client to the multi-sourcing computed from our method.
In addition to comparing their cost, several Key Performance Indicators (KPI) will be used as the generated stock-out, the probability of stock-out, the load of plants, etc.


\section{Simulation}


Simulation is based on real dataset from Argon Consulting’s clients.
We first retrieve the historical data and the current multi-sourcing to establish a comparison point.
%Objective of this part is to identify the available information when multi-sourcing decisions were made and only used this one.


The simulation emulates the behavior of people making multi-sourcing decisions.
First, we define plants data (capacities, internal production times, eligibility or not to be given the ability to produce items) and a forecast demand which is a function of the current period and of the past outcomes.
Then, we construct our model defined in \cref{chap:multi-sourcing:stochastic}.
Finally, we solve it and get a multi-sourcing decision.
This first step enables to compare current and computed multi-sourcing costs.


However, to show its practical efficiency, we fixed these decisions and emulated the behavior of people making production planning decisions (\ie mid-term decisions) subject to multi-sourcing decisions (\ie long-term decisions) already fixed.
We generate a sample of realizations of the demand.
For each realization, we solve a slightly modified version of the second stage (which is now deterministic) maximizing the fill rate service level and where $\AVaR_{1-\servicelvl}\bracket{\inventory_t^i}\le0$ is removed.
Indeed, in deterministic case, $\AVaR_{1-\servicelvl}\bracket{\inventory_t^i}\le0$ is equivalent to $\inventory_t^i\ge0$.
Yet, in many cases, deterministic model is infeasible.
(This is all the more foreseeable because we do not use robust constraint.)
Moreover, when making a production planning, if there is not enough flexibility or capacity, a production planning is always returned satisfying as well as possible a service level objective.
We then get several KPI such as fill rate service level, cycle service level, holding costs.


C++11 has been chosen for the implementations and Gurobi 6.5.1~\citet{gurobi} was used to solve the model on a PC with 32 processor Intel\textregistered\ Xeon\texttrademark\ E5-2667 @ 3.30GHz and 192Go RAM.


\section{Instance}


\subsection{Datasets}

In practice, we have access to every technical characteristics of the plant (like capacity, internal production time) or assignment costs.
We also have the forecast demand and the quantities really produced.
However, as usual, real demand may be slightly different from historical one.
Indeed, it is almost always impossible to trace if, after a stock-out, a client changes its mind for another item or do not buy anything.
% About opening costs, they are not straightforward.
% Discussions lead to consider the time loss to install assembly lines, to train employees and to ramp up production as the opening cost.

\cref{tab:multi-sourcing:instances-characteristics} summarize the characteristics of the two instances used for tests.
\begin{table}[h]
\begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}llr@{\extracolsep{\fill}}c@{\extracolsep{\fill}}rr@{\extracolsep{\fill}}c@{\extracolsep{\fill}}r@{\extracolsep{\fill}}}
\hline
\multicolumn{2}{c}{Instances characteristics} & \multicolumn{6}{c}{Instances}
\\
\cline{3-8}
&& \multicolumn{3}{c}{Mel} & \multicolumn{3}{c}{Lux}
\\
\hline
Number of plants & $\card{\plants}$ &&& $4$ &&& $27$
\\
Number of items & $\card{\REF}$ &&& $11$ &&& $100$
\\
Number of time steps & $\horizon$ &&& $3$ &&& $6$
\\
Historical demand & $\bar{\demand}_t^i$ & $4884$ &--& $19959$ & $0$ &--& $16996$
\\
Capacity of plants & $\capacity_p$ & $6156$ &--& $28969$ & $2213$ &--& $43416$ 
\\
Capacity for an item & $\ub_p^i$ & $1539$ &--& $7242$ & $721$ &--& $12753$ 
\\
Internal production time & $\rate_{pt}^i$ & $0.4$ &--& $1.1$ & $0.4$ &--& $9.0$
\\
Assignment cost & $\affect_p^i$ & $8392$ &--& $82196$ & $3516$ &--& $62234$ 
\\
\hline
\end{tabular*}
\caption{Instance characteristics}
\label{tab:multi-sourcing:instances-characteristics}
\end{table}

The parameter $\servicelvl$ which control the service level objective is chosen in $\crbracket{70\%,85\%,95\%}$.
The number $m$ of scenarios used to solve (2SA-$m$) is fixed to $100$ due to tractability restrictions.
The time limit to return a solution has been set to $20$ minutes because the clients wants to try several service level target.
Thus, the parameters for the heuristic are $N=10$ iterations to find $\alpha$ and $\tau=120$ second to find a solution of deterministic version~\eqref{eq:det-multi-sourcing} with demand scaled by $\alpha$.


\medskip


Mel dataset is a toy problem.
It is a simplified dataset created by a client of Argon Consulting to enable student from \'Ecole des Ponts to train and to propose new approach of multi-sourcing.
We use it as a test case due to its size.


\medskip


Lux dataset comes from the luxury industry.
In the original dataset, there were 500 different items.
However, the remaining 100 items of Lux dataset represent 80\% of the production (and of the sells).
Due to limited computational resources, the client prefers that the 400 items excluded from Lux dataset be mono-sourced to concentrate our effort on potential multi-sourced items.


Other rules are industrial ones.\vl{unclear}
For example, capacity of a plant to a specific item must never exceed 25\% of the plants capacity.
Indeed, if the demand for this item drastically drop, the plants must be able to rely on other item.
This constraint is included in the upper bound $\ub_{pt}^i$.


Finally, we compute a \emph{green field} multi-sourcing, \ie we do not take into account decrease of internal computation times due to ramp up production.
Argon Consulting's client want to compare its actual multi-sourcing to the ideal one.


\subsection{Demand distribution}
\label{sec:multi-sourcing:numerical-experiments:demand-distribution}

%\esgil{Completer après la réunion du 05/09 avec Fabrice, Frédéric et Vincent.}


As explained in \cref{chap:business-context}, we study the ability to face variations of the product mix and assume that we already known the cumulative working hours of production $\sum_{t=1}^{\horizon}\sum_{i\in\REF}\rate^i\va\demand_t^i$.
Since production rate are not the same between item, we deal with the production hours $\bracket{\va p_t^i}_{t,i}=\bracket{\rate^i\va\demand_t^i}_{t,i}$ as random variables instead of the demand $\bracket{\va\demand_t^i}_{t,i}$.


We generate randomness from historical data using \distrib distributions as in \cref{chap:PDP:numerical-experiments} and we refer to \cref{sec:PDP:numerical-experiments:drawing-realization-of-demand} for the properties of the distribution of the $\bracket{\va p_t^i}_{t,i}$ (\cref{prop:demand-distribution:properties}) and for the definitions of a generator of vectors with this distribution (\cref{proc:demand:initial-sampling}).


The parameters of the \distrib distribution used to generate the working hours of production are computing from the historical forecast demand and are equal to $\rate^i\bar{\demand}_t^i=\bar{p}_t^i$ for the $\tilde{p}_t^i$ and $\gamma$ is set equal to
\begin{equation}
  \gamma
  =
  v\frac
  {\sum_{t=1}^{\horizon}\sum_{i\in\REF} \sqrt{\frac{\bar{p}_0}{\bar{p}_t^i}-1}}
  {\sum_{t=1}^{\horizon}\sum_{i\in\REF} \bracket{\frac{\bar{p}_0}{\bar{p}_t^i}-1}}
\end{equation}
with $\bar{p}_0 = \sum_{t=1}^{\horizon}\sum_{i\in\REF}\rate^i\bar{\demand}_t^i$.
The parameter $\gamma$ is defined from another parameter $v$ which we call \emph{volatility} and which represents the ratio between standard deviation and expectation of a random variable.
It can be easily interpret by companies.
Justification of such a choice for $\gamma$ can be found in \cref{sec:PDP:numerical-experiments:instances:fitting-parameters}.



\medskip


As in \cref{chap:pdp:numerical-experiments}, results may depend on the number of generated scenarios.
Thus, we would like to apply the same method drawing a big number $M$ scenarios.
Then, we would use $K$-means algorithm (see \cref{sec:PDP:numerical-experiments:k-means}) to construct a set of 100 representative scenarios composed of the $K$ prototypes of each cluster.
Each prototype gives a scenario weighted by the number of scenarios in its cluster divided by $M$.
For lack of time, we do not yet implemented $K$-mean algorithm.

% Since we know the historical demand, the generate demand of an item at a period should have the same expectation which explains \cref{enum:multi-sourcing:random-demand-property:expectation}.
% \cref{enum:multi-sourcing:random-demand-property:constant-volume} is justified by our study of flexibility.
% Indeed, as explained in \cref{chap:business-context}, we study the ability to face variations of the product mix and assume that we already known the cumulative working hours of production $\sum_{t=1}^{\horizon}\sum_{i\in\REF}\rate^i\va\demand_t^i$.
% In \label{enum:multi-sourcing:random-demand-property:variance}, there remains a unique unfixed parameter $\gamma$ which enables to chose the level of randomness. As we can see in \cref{eq:multi-sourcing:numerical-experiments:demand:variance}, the greater $\gamma$ is, the greater the variances of demand are.


\section{Numerical results}
\label{sec:multi-sourcing:numerical-experiments:numerical-results}


\esgil{Complete with KPI given by Fabrice and Pierre-Fabrice.}


Simulation results for Mel dataset without using the heuristic are given in \cref{tab:multi-sourcing:results:mel:without-heuristic} and using heuristic in \cref{tab:multi-sourcing:results:mel:with-heuristic}.
Simulation results for Lux dataset using heuristic are given in \cref{tab:multi-sourcing:results:lux:with-heuristic}.


We remind that parameter $\servicelvl$ enables to control the desired service level.
The volatility is the value used in the Dirichlet model used to generate randomness (see \cref{sec:multi-sourcing:numerical-experiments:generate-randomness}).


There are two ways of measuring the output.
First, they can be made \emph{in-sample}.
In this cases, the solution of the Program~\eqref{eq:stoch-multi-sourcing:linearized} found is used to compute the KPI as if it stand for the whole possible realizations of the randomness.
In the other hand, they can be made \emph{out-of-sample}.
In this case, a new linear program is created from the deterministic version~\eqref{eq:det-multi-sourcing} and from the returned assignment $\bracket{\open_p^{i*}}_{p,i}$.
Then, we generate $n=10000$ realizations of demand and solve $n$ times the following deterministic program (one for each realization of demand)
\begin{subequations}\label{eq:det-multi-sourcing:second-step:second-step}
  \begin{align+}
    \min\quad & \rlap{$\ds \sum_{i\in\REF} w^i f\bracket{(\quantity_{pt}^i)_{p,t},(\inventory_t^i)_t}$}
    \label{eq:det-multi-sourcing:second-step:objective}
    \\
    \st\quad & \ds \inventory_t^i = \inventory_{t-1}^i + \sum_{p\in\plants}\quantity_{pt}^i - \demand_t^i && \forall t\in\range{\horizon},\ \forall i\in\REF,
    \label{eq:det-multi-sourcing:second-step:inventory-dynamic}
    \\
    & \ds \sum_{i\in\REF}\rate_{pt}^i\quantity_{pt}^i \leq \capacity_{pt} && \forall t\in\range{\horizon},\ \forall p\in\plants,
    \label{eq:det-multi-sourcing:second-step:capacity}
    \\
    & \ds \lb_{pt}^i \open_p^{i*} \le \rate_{pt}^i\quantity_{pt}^i \le \ub_{pt}^i \open_p^{i*} && \forall t\in\range{\horizon},\ \forall p\in\plants, \forall i\in\REF,
    \label{eq:det-multi-sourcing:second-step:big-M}
    \\
    & \ds \quantity_{pt}^i \ge 0 && \forall t\in\range{\horizon},\ \forall p\in\plants, \forall i\in\REF.
    \label{eq:det-multi-sourcing:second-step:positivity}
  \end{align+}
\end{subequations}
where $f\bracket{(\quantity_{pt}^i)_{p,t},(\inventory_t^i)_t}$ is the fill rate service level of item $i$ given by
\begin{equation}
  f\bracket{(\quantity_{pt}^i)_{p,t},(\inventory_t^i)_t} = \frac{\sum_{t=1}^{\horizon}\min\bracket{(\inventory_{t-1}^i)^++\quantity_t^i,\ \demand_t^i}}{\sum_{t=1}^{\horizon}\demand_t^i}
\end{equation}
and $w^i$ is the weight of item $i$ in the global fill rate service level KPI and is given by
\begin{equation}\label{eq:multi-sourcing:numerical-experiments:KPI:weight}
  w^i=\frac{\rate^i}{\sum_{j\in\REF}\rate^j}.
\end{equation}
Problem~\eqref{eq:det-multi-sourcing:second-step:second-step} can clearly be written as a linear program with only continuous variables.

\medskip

The list of outputs are decomposed as follow.
\begin{itemize}
  \item \emph{Solver best value} (resp. \emph{heuristic value}) gives the value returned by the solver (resp. the heuristic) at the end of the time allowed to find a solution.
  \item $\prob\sqbracket{stock\ge0}$ measures in-sample the probability that inventory \vl{of a random item at a random time} is positive.
  \begin{equation}
    \prob\sqbracket{stock\ge0}=\frac{1}{\horizon\times\card{\REF}\times\card{\scenarios}}\sum_{t=1}^{\horizon}\sum_{i\in\REF}\sum_{\omega\in\scenarios} \mathbb{1}_{\crbracket{\inventory_{t,\omega}^i\ge0}}
  \end{equation}
  $\prob\sqbracket{stock\ge0}$ finally returns the average over all periods and all items.\vl{unnecessary}
  \item \emph{Cycle service level} and \emph{fill rate service level} are measured out-of-sample.
  They are computed using \cref{eq:pdp:numerical-experiments:KPI:fill-rate-service-level} and \cref{eq:pdp:numerical-experiments:KPI:cycle-service-level} replacing $w^i$ by the expression given by \cref{eq:multi-sourcing:numerical-experiments:KPI:weight}.
  Then, the table\vl{which} shows the average over all runs of the simulation.
  \item \emph{GAP} is the gap between the best value returned by the solver or the heuristic and the best known lower bound on the problem.
  \item \emph{Solver lower  bound} is the best lower bound found by the solver when the solver is frontally used to solve Program \eqref{eq:stoch-multi-sourcing:linearized}.
  \item \emph{Continuous relaxation} is the value of the continuous relaxation of Program \eqref{eq:stoch-multi-sourcing:linearized}.
  \item \emph{Time for bound} is the time needed to get the bound written on the previous line of the table.
\end{itemize}


\begin{table}[h]
\begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}c|r|r|r|r|r|r|l@{\extracolsep{\fill}}}
$\beta$ & \multicolumn{6}{c|}{Volatility} & \multicolumn{1}{c}{Output}
\\
& \multicolumn{1}{c|}{1\%} & \multicolumn{1}{c|}{5\%} & \multicolumn{1}{c|}{10\%} & \multicolumn{1}{c|}{30\%} & \multicolumn{1}{c|}{50\%} & \multicolumn{1}{c|}{80\%} & 
\\ \hline
70\% & 953 & 967 & 1011 & 1034 & 1134 & 1381 & Solver best value \hfill {\scriptsize($\times10^3$)}
\\
     & 93.8 & 93.5 & 93.3 & 91.2 & 90.1 & 91.4 & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 99.7 & 100.0 & 100.0 & 98.7 & 97.5 & 97.5 & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.7 & 99.2 & 98.8 & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
85\% & 957 & 957 & 1000 & 1087 & 1188 & \multicolumn{1}{c|}{$\infty$} & Solver best value \hfill {\scriptsize($\times10^3$)}
\\ \cdashline{2-8}[2pt/2pt]
     & 17.5 & 15.0 & 18.1 & 17.7 & 11.3 & \multicolumn{1}{c|}{--} & GAP (best known bound) \hfill {\scriptsize(in \%)}
\\
     & 790 & 813 & 819 & 895 & 1054 & \multicolumn{1}{c|}{--} & Solver lower bound \hfill {\scriptsize($\times10^3$)}
\\
     & 1200 & 1200 & 1200 & 1200 & 1200 & \multicolumn{1}{c|}{--} & Time for bound \hfill {\scriptsize(in s)}
\\ \cdashline{2-8}[2pt/2pt]
     & 98.5 & 98.1 & 97.6 & 96.5 & 95.9 & \multicolumn{1}{c|}{--} & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.4 & 98.6 & \multicolumn{1}{c|}{--} & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.9 & 99.6 & \multicolumn{1}{c|}{--} & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
95\% & 954 & 956 & 997 & 1173 & 1371 & \multicolumn{1}{c|}{$\infty$} & Solver best value \hfill {\scriptsize($\times10^3$)}
\\
     & 99.6 & 99.6 & 99.3 & 99.0 & 99.0 & \multicolumn{1}{c|}{--} & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 99.8 & 99.8 & 99.6 & \multicolumn{1}{c|}{--} & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 100.0 & 99.9 & \multicolumn{1}{c|}{--} & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
\end{tabular*}
\caption{Results for Mel dataset (without heuristic)}
\label{tab:multi-sourcing:results:mel:without-heuristic}
\end{table}



\begin{table}[h]
\begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}c|r|r|r|r|r|r|l@{\extracolsep{\fill}}}
$\beta$ & \multicolumn{6}{c|}{Volatility} & \multicolumn{1}{c}{Output}
\\
& \multicolumn{1}{c|}{1\%} & \multicolumn{1}{c|}{5\%} & \multicolumn{1}{c|}{10\%} & \multicolumn{1}{c|}{30\%} & \multicolumn{1}{c|}{50\%} & \multicolumn{1}{c|}{80\%} & 
\\ \hline
70\% & 1152 & 1176 & 1156 & 1136 & 1541 & 1640 & Heuristic value \hfill {\scriptsize($\times10^3$)}
\\
     & 95.5 & 93.8 & 92.7 & 89.7 & 88.8 & 90.1 & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.8 & 99.8 & 99.3 & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.0 & 99.3 & 98.5 & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
85\% & 1152 & 1134 & 1146 & 1112 & 1230 & \multicolumn{1}{c|}{$\infty$} & Heuristic value \hfill {\scriptsize($\times10^3$)}
\\ \cdashline{2-8}[2pt/2pt]
     & 31.4 & 28.3 & 28.5 & 19.5 & 14.3 & \multicolumn{1}{c|}{--} & GAP (best known bound) \hfill {\scriptsize(in \%)}
\\
     & 673 & 707 & 686 & 797 & 900 & 1144 & Continuous relaxation \hfill {\scriptsize($\times10^3$)}
\\
     & 3.8 & 13.8 & 3.5 & 2.4 & 13.7 & 3.6 & Time for bound \hfill {\scriptsize(in s)}
\\ \cdashline{2-8}[2pt/2pt]
     & 97.7 & 97.2 & 96.6 & 96.2 & 95.7 & \multicolumn{1}{c|}{--} & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.9 & 99.6 & \multicolumn{1}{c|}{--} & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.5 & 98.7 & \multicolumn{1}{c|}{--} & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
95\% & 1152 & 968 & 1021 & 1210 & 1396 & \multicolumn{1}{c|}{$\infty$} & Heuristic value \hfill {\scriptsize($\times10^3$)}
\\
     & 99.2 & 99.8 & 99.8 & 99.0 & 99.1 & \multicolumn{1}{c|}{--} & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 100.0 & 99.9 & \multicolumn{1}{c|}{--} & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 100.0 & 100.0 & 100.0 & 99.8 & 99.6 & \multicolumn{1}{c|}{--} & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
\end{tabular*}
\caption{Results for Mel dataset (with heuristic)}
\label{tab:multi-sourcing:results:mel:with-heuristic}
\end{table}



\begin{table}[h]
\begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}c|r|r|r|r|r|r|l@{\extracolsep{\fill}}}
$\beta$ & \multicolumn{6}{c|}{Volatility} & \multicolumn{1}{c}{Output}
\\
& \multicolumn{1}{c|}{1\%} & \multicolumn{1}{c|}{5\%} & \multicolumn{1}{c|}{10\%} & \multicolumn{1}{c|}{30\%} & \multicolumn{1}{c|}{50\%} & \multicolumn{1}{c|}{80\%} & 
\\ \hline
70\% & 1392 & 1409 & 1420 & 1476 & 1624 & 1861 & Heuristic value \hfill {\scriptsize($\times10^3$)}
\\
     & 99.4 & 99.3 & 99.2 & 98.7 & 98.6 & 98.5 & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 80.2 & 80.4 & 80.6 & 81.1 & 81.3 & 82.0 & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 87.2 & 87.1 & 86.8 & 86.5 & 88.0 & 87.3 & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
85\% & 1392 & 1409 & 1407 & 1516 & 1708 & 1997 & Heuristic value \hfill {\scriptsize($\times10^3$)}
\\ \cdashline{2-8}[2pt/2pt]
     & \multicolumn{1}{c|}{--} & 24.1 & 22.3 & 24.7 & \multicolumn{1}{c|}{--} & \multicolumn{1}{c|}{--} & GAP (best known bound) \hfill {\scriptsize(in \%)}
\\
     & \multicolumn{1}{c|}{--} & 1070 & 1084 & 1142 & \multicolumn{1}{c|}{--} & \multicolumn{1}{c|}{--} & Continuous relaxation \hfill {\scriptsize($\times10^3$)}
\\
     & 86400 & 28728 & 31277 & 51399 & 86400 & 86400 & Time for bound \hfill {\scriptsize(in s)}
\\ \cdashline{2-8}[2pt/2pt]
     & 99.9 & 99.8 & 99.8 & 99.6 & 99.5 & 99.4 & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 80.2 & 80.4 & 80.6 & 81.1 & 82.0 & 81.1 & Cycle service level \hfill {\scriptsize(in \%)}
\\
     & 87.2 & 87.0 & 86.3 & 87.8 & 87.2 & 87.6 & Fill rate service level  \hfill {\scriptsize(in \%)}
\\ \hline
95\% & 1392 & 1420 & 1421 & 1624 & 1900 & 2382 & Heuristic value \hfill {\scriptsize($\times10^3$)}
\\
     & 100.0 & 100.0 & 99.9 & 99.9 & 99.9 & 99.9 & $\prob\sqbracket{stock\ge0}$ \hfill {\scriptsize(in \%)}
\\
     & 80.2 & 80.7 & 80.8 & 81.3 & 81.8 & 81.9 & Cycle service level  \hfill {\scriptsize(in \%)}
\\
     & 87.2 & 86.7 & 88.0 & 88.3 & 88.2 & 87.5 & Fill rate service level \hfill {\scriptsize(in \%)}
\\ \hline
\end{tabular*}
\caption{Results for Lux dataset (with heuristic)}
\label{tab:multi-sourcing:results:lux:with-heuristic}
\end{table}


First, note that we do not provide results for Lux dataset without the heuristic.
Indeed, we were not able to find a solution in the allowed time (20 minutes).
Moreover, for the Lux dataset, it is even impossible to compute the continuous relaxation in less than 24 hours for a volatility equal to $1\%$, $50\%$ and $80\%$.


Second important point, on small data set, the frontal used of a solver gives always better results than the heuristic even if this gap decrease with the increase of volatility.
However, on huge dataset, we never get a solution from a frontal used of a solver.


Although it is not a proof, the values returned by $\prob\sqbracket{stock\ge0}$ show on some examples that the satisfaction of $\AVaR$ constraint implies the satisfaction of probabilistic constraint.


Finally, we see that aiming at $70\%$ or aiming at $95\%$ does not really change the maximal fill rate service level or the maximal cycle service level that can be reached.
However, it really changes the cost of the assignment.


\esgil{Refaire des tests avec des valeur plus faibles de $\servicelvl$}


